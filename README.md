# Reinforcement-Learning-Deep-Reinforcement-Learning-from-Human-Preferences
Interacting with the real world may only be thought off if we understand how to communicate the underlying complex purposes of each systems and how they interact with each other. Reinforcement learning based systems interact with their environments and thus we explore in this article goals of human preferences between several trajectory segments.         Indeed we will see that this method can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than $1\%$ of our agentâ€™s interactions with the environment. This reduces the cost of human monitoring enough that it can be practically applied to modern RL systems. To demonstrate the versatility of the approach, we show that we can successfully train new complex  behaviors with about an hour of human time. These behaviors and environments are significantly more complex than any  previously learned behavior and environment from human feedback.
